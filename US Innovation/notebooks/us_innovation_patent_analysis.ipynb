{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eea645b",
   "metadata": {},
   "source": [
    "# US Innovation: Patent Event Studies and Panel Regressions\n",
    "\n",
    "This notebook reproduces the analyses from the Stata scripts:\n",
    "\n",
    "1. `event_study_all_patents.do`\n",
    "2. `panel_regressions_6675.do`\n",
    "3. `panel_regresssions_HHI_final .do`\n",
    "\n",
    "It assumes the corresponding `.dta` files have been copied into the `../data` directory. Sections below follow the original workflow order and document each transformation so the analysis is portfolio-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cd7273",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Setup](#Setup)\n",
    "- [1. Event Study](#1-Event-Study)\n",
    "- [2. Panel Regressions (6675)](#2-Panel-Regressions-6675)\n",
    "- [3. Panel Regressions with HHI Splits](#3-Panel-Regressions-with-HHI-Splits)\n",
    "- [Appendix](#Appendix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c113f13b",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e308e9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "try:\n",
    "    from linearmodels.iv import IV2SLS\n",
    "except ImportError as exc:\n",
    "    raise ImportError(\n",
    "        \"Install `linearmodels` via `pip install linearmodels` to run the IV specifications.\"\n",
    "    ) from exc\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"talk\")\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.float_format\", \"{:,.4f}\".format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c58de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ROOT = Path.cwd().resolve().parent\n",
    "DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "FIGURE_DIR = PROJECT_ROOT / \"figures\"\n",
    "TABLE_DIR = PROJECT_ROOT / \"tables\"\n",
    "\n",
    "for path in (FIGURE_DIR, TABLE_DIR):\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_DATA = {\n",
    "    \"panel\": DATA_DIR / \"intermediate\" / \"panel\" / \"built.dta\",\n",
    "    \"defcon\": DATA_DIR / \"intermediate\" / \"defcon_patent_merge_county_year_final.dta\",\n",
    "    \"panel5\": DATA_DIR / \"intermediate\" / \"panel\" / \"built5.dta\",\n",
    "    \"hhi\": DATA_DIR / \"intermediate\" / \"hhi_aggregate_all1_pre80.dta\",\n",
    "}\n",
    "\n",
    "missing = {name: path for name, path in RAW_DATA.items() if not path.exists()}\n",
    "if missing:\n",
    "    print(\"⚠️ Update `RAW_DATA` if your directory structure differs. Missing files detected:\")\n",
    "    for name, path in missing.items():\n",
    "        print(f\" - {name}: {path}\")\n",
    "else:\n",
    "    print(\"All expected source files found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b553a23",
   "metadata": {},
   "source": [
    "### Helper utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3061411",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_fe_terms(fe_vars):\n",
    "    return [f\"C({col})\" for col in fe_vars]\n",
    "\n",
    "\n",
    "def build_ols_formula(outcome, key_var, controls=None, fe=(\"county_fips\", \"fyear\")):\n",
    "    controls = controls or []\n",
    "    fe_terms = build_fe_terms(fe)\n",
    "    rhs_parts = [key_var] + controls + fe_terms\n",
    "    return f\"{outcome} ~ \" + \" + \".join(rhs_parts)\n",
    "\n",
    "\n",
    "def build_iv_formula(\n",
    "    outcome,\n",
    "    endog,\n",
    "    instruments,\n",
    "    controls=None,\n",
    "    fe=(\"county_fips\", \"fyear\"),\n",
    "):\n",
    "    controls = controls or []\n",
    "    endog_terms = endog if isinstance(endog, (list, tuple)) else [endog]\n",
    "    instrument_terms = instruments if isinstance(instruments, (list, tuple)) else [instruments]\n",
    "    fe_terms = build_fe_terms(fe)\n",
    "    rhs = [\"1\"] + controls + fe_terms\n",
    "    endog_expr = \" + \\\".join(endog_terms)\n",
    "    instr_expr = \" + \\\".join(instrument_terms)\n",
    "    base = \" + \\\".join(rhs)\n",
    "    return f\"{outcome} ~ {base} + [{endog_expr} ~ {instr_expr}]\"\n",
    "\n",
    "\n",
    "def tidy_result(result, term, model_label):\n",
    "    if not hasattr(result, \"params\"):\n",
    "        raise ValueError(\"Result object does not expose parameters.\")\n",
    "    params = result.params\n",
    "    if term not in params.index:\n",
    "        raise KeyError(\n",
    "            f\"Term `{term}` not found in model {model_label}. Available terms: {list(params.index)}\"\n",
    "        )\n",
    "    if hasattr(result, \"bse\"):\n",
    "        se = result.bse[term]\n",
    "    elif hasattr(result, \"std_errors\"):\n",
    "        se = result.std_errors[term]\n",
    "    else:\n",
    "        raise AttributeError(\"Cannot locate standard errors on result object.\")\n",
    "    if hasattr(result, \"pvalues\"):\n",
    "        p_value = result.pvalues[term]\n",
    "    else:\n",
    "        p_value = np.nan\n",
    "    coef = params[term]\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"model\": model_label,\n",
    "            \"term\": term,\n",
    "            \"coef\": coef,\n",
    "            \"std_err\": se,\n",
    "            \"ci_low\": coef - 1.96 * se,\n",
    "            \"ci_high\": coef + 1.96 * se,\n",
    "            \"p_value\": p_value,\n",
    "            \"nobs\": getattr(result, \"nobs\", np.nan),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def summarize_models(rows):\n",
    "    table = pd.DataFrame(rows).set_index(\"model\")\n",
    "    return table[[\"coef\", \"std_err\", \"ci_low\", \"ci_high\", \"p_value\", \"nobs\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c25e2",
   "metadata": {},
   "source": [
    "## 1. Event Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b63f",
   "metadata": {},
   "source": [
    "This section rebuilds the treatment definition from the spending surge, applies the semiconductor-intensive sample restriction, and replicates the difference-in-differences regressions together with the trend and event-time visuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7693bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = (\n",
    "    pd.read_stata(RAW_DATA[\"panel\"])\n",
    "    .merge(pd.read_stata(RAW_DATA[\"defcon\"]), on=[\"county_fips\", \"fyear\"], how=\"inner\")\n",
    ")\n",
    "\n",
    "event_df = event_df.loc[event_df[\"fyear\"].between(1965, 2003)].copy()\n",
    "event_df[\"semi_intens\"] = event_df.groupby(\"county_fips\")[\"semi_intens\"].transform(\"max\")\n",
    "event_df = event_df.loc[event_df[\"semi_intens\"] == 1].copy()\n",
    "event_df[\"county_id\"] = event_df.groupby(\"county_fips\").ngroup()\n",
    "\n",
    "mean_spend1 = (\n",
    "    event_df.loc[event_df[\"fyear\"].between(1976, 1981)]\n",
    "    .groupby(\"county_fips\")[\"total_dollars\"]\n",
    "    .mean()\n",
    ")\n",
    "mean_spend2 = (\n",
    "    event_df.loc[event_df[\"fyear\"].between(1981, 1989)]\n",
    "    .groupby(\"county_fips\")[\"total_dollars\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "event_df[\"mean_spend1\"] = event_df[\"county_fips\"].map(mean_spend1)\n",
    "event_df[\"mean_spend2\"] = event_df[\"county_fips\"].map(mean_spend2)\n",
    "event_df[\"surge\"] = event_df[\"mean_spend2\"] - event_df[\"mean_spend1\"]\n",
    "\n",
    "surge_stats = (\n",
    "    event_df.drop_duplicates(\"county_fips\")[[\"county_fips\", \"surge\"]]\n",
    "    .dropna()\n",
    "    .set_index(\"county_fips\")\n",
    ")\n",
    "\n",
    "surge_thresholds = surge_stats[\"surge\"].agg([\"mean\", \"std\", \"median\"])\n",
    "surge_thresholds[\"mean_plus_sd\"] = surge_thresholds[\"mean\"] + surge_thresholds[\"std\"]\n",
    "surge_thresholds[\"mean_plus_half_sd\"] = surge_thresholds[\"mean\"] + surge_thresholds[\"std\"] / 2\n",
    "\n",
    "surge_cutoff = surge_thresholds[\"median\"]\n",
    "event_df[\"treated\"] = (event_df[\"surge\"] > surge_cutoff).astype(int)\n",
    "event_df[\"after\"] = (event_df[\"fyear\"] > 1981).astype(int)\n",
    "event_df[\"treatment\"] = (event_df[\"treated\"] * event_df[\"after\"]).astype(int)\n",
    "\n",
    "surge_thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9521cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "did_formula_patents = build_ols_formula(\"num_patents\", \"treatment\")\n",
    "did_patents = smf.ols(did_formula_patents, data=event_df).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": event_df[\"county_fips\"]}\n",
    ")\n",
    "\n",
    "did_formula_cites = build_ols_formula(\"w_cites_sub\", \"treatment\")\n",
    "did_cites = smf.ols(did_formula_cites, data=event_df).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": event_df[\"county_fips\"]}\n",
    ")\n",
    "\n",
    "did_results = summarize_models(\n",
    "    [\n",
    "        tidy_result(did_patents, \"treatment\", \"Patents (DiD)\"),\n",
    "        tidy_result(did_cites, \"treatment\", \"Citation-weighted (DiD)\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "did_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db223ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = (\n",
    "    event_df.groupby([\"fyear\", \"treated\"])[\"w_cites_sub\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"treated\": \"treated_group\"})\n",
    ")\n",
    "trend[\"treated_group\"] = trend[\"treated_group\"].map({0: \"Control\", 1: \"Treated\"})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "sns.lineplot(data=trend, x=\"fyear\", y=\"w_cites_sub\", hue=\"treated_group\", ax=ax)\n",
    "ax.axvline(1981, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax.set(\n",
    "    title=\"Average Citation-weighted Patents by Treatment Group\",\n",
    "    xlabel=\"Year\",\n",
    "    ylabel=\"Average w_cites_sub\",\n",
    ")\n",
    "ax.legend(title=\"Group\")\n",
    "fig.tight_layout()\n",
    "fig_path = FIGURE_DIR / \"event_study_trend.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "fig_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdd187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_YEAR = 1981\n",
    "WINDOW = range(-10, 11)\n",
    "\n",
    "event_df[\"event_time\"] = event_df[\"fyear\"] - BASE_YEAR\n",
    "for k in WINDOW:\n",
    "    col = f\"lead_lag_{k}\"\n",
    "    event_df[col] = np.where(\n",
    "        (event_df[\"event_time\"] == k) & (event_df[\"treated\"] == 1),\n",
    "        1,\n",
    "        0,\n",
    "    )\n",
    "\n",
    "event_terms = [f\"lead_lag_{k}\" for k in WINDOW if k != 0]\n",
    "event_formula = \"w_cites_sub ~ \" + \" + \".join(event_terms + [\"C(county_fips)\", \"C(fyear)\"])\n",
    "event_model = smf.ols(event_formula, data=event_df).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": event_df[\"county_fips\"]}\n",
    ")\n",
    "\n",
    "event_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"event_time\": [k for k in WINDOW if k != 0],\n",
    "        \"coef\": [event_model.params[f\"lead_lag_{k}\"] for k in WINDOW if k != 0],\n",
    "        \"std_err\": [event_model.bse[f\"lead_lag_{k}\"] for k in WINDOW if k != 0],\n",
    "    }\n",
    ")\n",
    "event_summary[\"ci_low\"] = event_summary[\"coef\"] - 1.96 * event_summary[\"std_err\"]\n",
    "event_summary[\"ci_high\"] = event_summary[\"coef\"] + 1.96 * event_summary[\"std_err\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axvline(-0.5, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "ax.axhline(0, color=\"gray\", linestyle=\":\", linewidth=1)\n",
    "ax.fill_between(\n",
    "    event_summary[\"event_time\"],\n",
    "    event_summary[\"ci_low\"],\n",
    "    event_summary[\"ci_high\"],\n",
    "    alpha=0.3,\n",
    "    color=\"#1f77b4\",\n",
    ")\n",
    "ax.plot(event_summary[\"event_time\"], event_summary[\"coef\"], marker=\"o\", color=\"#1f77b4\")\n",
    "ax.set(\n",
    "    title=\"Event-time Effects on Citation-weighted Patents\",\n",
    "    xlabel=\"Years relative to 1981\",\n",
    "    ylabel=\"Coefficient (vs. 1981 baseline)\",\n",
    ")\n",
    "fig.tight_layout()\n",
    "event_fig_path = FIGURE_DIR / \"event_time_coefficients.png\"\n",
    "fig.savefig(event_fig_path, dpi=300)\n",
    "event_summary.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113126c",
   "metadata": {},
   "source": [
    "## 2. Panel Regressions (6675)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60c33ac",
   "metadata": {},
   "source": [
    "We recreate the two-stage empirical strategy from the baseline Stata script: first diagnosing the instrument, then reporting the OLS and IV specifications with progressively richer fixed effects and controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f08a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel5 = pd.read_stata(RAW_DATA[\"panel5\"]).copy()\n",
    "panel5[\"state_yr\"] = panel5[\"state\"].astype(str) + \"_\" + panel5[\"fyear\"].astype(int).astype(str)\n",
    "panel5.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910abc79",
   "metadata": {},
   "source": [
    "### First-stage diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c02431",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_stage = panel5.query(\n",
    "    \"semi_intens == 1 and fyear > 1975 and ltotal_dollars > 0 and lspending_6675_iv > 0\"\n",
    ").copy()\n",
    "\n",
    "first_stage[\"lspending_6675_iv_centered\"] = (\n",
    "    first_stage[\"lspending_6675_iv\"] - first_stage[\"lspending_6675_iv\"].mean()\n",
    ")\n",
    "\n",
    "resid_lt_model = smf.ols(\"ltotal_dollars ~ C(fyear)\", data=first_stage).fit()\n",
    "first_stage[\"resid_lt\"] = resid_lt_model.resid\n",
    "\n",
    "resid_iv_model = smf.ols(\"lspending_6675_iv_centered ~ C(fyear)\", data=first_stage).fit()\n",
    "first_stage[\"resid_iv\"] = resid_iv_model.resid\n",
    "\n",
    "first_stage[[\"ltotal_dollars\", \"lspending_6675_iv_centered\", \"resid_lt\", \"resid_iv\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853b9429",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.scatterplot(data=first_stage, x=\"resid_iv\", y=\"resid_lt\", alpha=0.5, ax=ax[0])\n",
    "sns.regplot(\n",
    "    data=first_stage,\n",
    "    x=\"resid_iv\",\n",
    "    y=\"resid_lt\",\n",
    "    scatter=False,\n",
    "    line_kws={\"color\": \"black\"},\n",
    "    ax=ax[0],\n",
    ")\n",
    "ax[0].set(\n",
    "    title=\"Residualized Relationship\",\n",
    "    xlabel=\"Residual IV (centered)\",\n",
    "    ylabel=\"Residual log spending\",\n",
    ")\n",
    "\n",
    "sns.scatterplot(data=first_stage, x=\"lspending_6675_iv\", y=\"ltotal_dollars\", alpha=0.3, ax=ax[1])\n",
    "sns.regplot(\n",
    "    data=first_stage,\n",
    "    x=\"lspending_6675_iv\",\n",
    "    y=\"ltotal_dollars\",\n",
    "    scatter=False,\n",
    "    line_kws={\"color\": \"black\"},\n",
    "    ax=ax[1],\n",
    ")\n",
    "ax[1].set(\n",
    "    title=\"Raw Relationship\",\n",
    "    xlabel=\"Log IV spending\",\n",
    "    ylabel=\"Log direct spending\",\n",
    ")\n",
    "\n",
    "fig.tight_layout()\n",
    "fig_path = FIGURE_DIR / \"first_stage_checks.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "fig_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a8a0d",
   "metadata": {},
   "source": [
    "### Intensive-margin regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a86eb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_sample = panel5.query(\"semi_intens == 1 and fyear > 1975\").copy()\n",
    "all_sample = panel5.query(\"fyear > 1975\").copy()\n",
    "\n",
    "controls = [\"avg_wages\", \"pop\", \"emp\"]\n",
    "\n",
    "semi_rows = []\n",
    "\n",
    "model = smf.ols(build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\"), data=semi_sample).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": semi_sample[\"county_fips\"]}\n",
    ")\n",
    "semi_rows.append(tidy_result(model, \"ltotal_dollars\", \"Semi counties – OLS (simple)\"))\n",
    "\n",
    "iv_formula = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"log_spending_6675_iv\",\n",
    "    fe=(\"county_fips\", \"fyear\"),\n",
    ")\n",
    "iv_model = IV2SLS.from_formula(iv_formula, data=semi_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=semi_sample[\"county_fips\"]\n",
    ")\n",
    "semi_rows.append(tidy_result(iv_model, \"ltotal_dollars\", \"Semi counties – IV (simple)\"))\n",
    "\n",
    "model_full = smf.ols(\n",
    "    build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\", controls),\n",
    "    data=semi_sample,\n",
    ").fit(cov_type=\"cluster\", cov_kwds={\"groups\": semi_sample[\"county_fips\"]})\n",
    "semi_rows.append(tidy_result(model_full, \"ltotal_dollars\", \"Semi counties – OLS (controls)\"))\n",
    "\n",
    "iv_formula_full = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"log_spending_6675_iv\",\n",
    "    controls=controls,\n",
    ")\n",
    "iv_model_full = IV2SLS.from_formula(iv_formula_full, data=semi_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=semi_sample[\"county_fips\"]\n",
    ")\n",
    "semi_rows.append(tidy_result(iv_model_full, \"ltotal_dollars\", \"Semi counties – IV (controls)\"))\n",
    "\n",
    "model_state = smf.ols(\n",
    "    build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\", controls, fe=(\"county_fips\", \"fyear\", \"state_yr\")),\n",
    "    data=semi_sample,\n",
    ").fit(cov_type=\"cluster\", cov_kwds={\"groups\": semi_sample[\"county_fips\"]})\n",
    "semi_rows.append(tidy_result(model_state, \"ltotal_dollars\", \"Semi counties – OLS (state-year FE)\"))\n",
    "\n",
    "iv_formula_state = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"log_spending_6675_iv\",\n",
    "    controls=controls,\n",
    "    fe=(\"county_fips\", \"fyear\", \"state_yr\"),\n",
    ")\n",
    "iv_model_state = IV2SLS.from_formula(iv_formula_state, data=semi_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=semi_sample[\"county_fips\"]\n",
    ")\n",
    "semi_rows.append(tidy_result(iv_model_state, \"ltotal_dollars\", \"Semi counties – IV (state-year FE)\"))\n",
    "\n",
    "semi_table = summarize_models(semi_rows)\n",
    "semi_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "\n",
    "model = smf.ols(build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\"), data=all_sample).fit(\n",
    "    cov_type=\"cluster\", cov_kwds={\"groups\": all_sample[\"county_fips\"]}\n",
    ")\n",
    "all_rows.append(tidy_result(model, \"ltotal_dollars\", \"All counties – OLS (simple)\"))\n",
    "\n",
    "a_iv_formula = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"lspending_6675_iv\",\n",
    ")\n",
    "a_iv_model = IV2SLS.from_formula(a_iv_formula, data=all_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=all_sample[\"county_fips\"]\n",
    ")\n",
    "all_rows.append(tidy_result(a_iv_model, \"ltotal_dollars\", \"All counties – IV (simple)\"))\n",
    "\n",
    "model_full = smf.ols(\n",
    "    build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\", controls),\n",
    "    data=all_sample,\n",
    ").fit(cov_type=\"cluster\", cov_kwds={\"groups\": all_sample[\"county_fips\"]})\n",
    "all_rows.append(tidy_result(model_full, \"ltotal_dollars\", \"All counties – OLS (controls)\"))\n",
    "\n",
    "a_iv_formula_full = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"lspending_6675_iv\",\n",
    "    controls=controls,\n",
    ")\n",
    "a_iv_model_full = IV2SLS.from_formula(a_iv_formula_full, data=all_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=all_sample[\"county_fips\"]\n",
    ")\n",
    "all_rows.append(tidy_result(a_iv_model_full, \"ltotal_dollars\", \"All counties – IV (controls)\"))\n",
    "\n",
    "model_state = smf.ols(\n",
    "    build_ols_formula(\"lw_cites_sub\", \"ltotal_dollars\", controls, fe=(\"county_fips\", \"fyear\", \"state_yr\")),\n",
    "    data=all_sample,\n",
    ").fit(cov_type=\"cluster\", cov_kwds={\"groups\": all_sample[\"county_fips\"]})\n",
    "all_rows.append(tidy_result(model_state, \"ltotal_dollars\", \"All counties – OLS (state-year FE)\"))\n",
    "\n",
    "a_iv_formula_state = build_iv_formula(\n",
    "    \"lw_cites_sub\",\n",
    "    \"ltotal_dollars\",\n",
    "    \"lspending_6675_iv\",\n",
    "    controls=controls,\n",
    "    fe=(\"county_fips\", \"fyear\", \"state_yr\"),\n",
    ")\n",
    "a_iv_model_state = IV2SLS.from_formula(a_iv_formula_state, data=all_sample).fit(\n",
    "    cov_type=\"clustered\", clusters=all_sample[\"county_fips\"]\n",
    ")\n",
    "all_rows.append(tidy_result(a_iv_model_state, \"ltotal_dollars\", \"All counties – IV (state-year FE)\"))\n",
    "\n",
    "all_table = summarize_models(all_rows)\n",
    "all_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c31d0d",
   "metadata": {},
   "source": [
    "## 3. Panel Regressions with HHI Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015dfa8b",
   "metadata": {},
   "source": [
    "The final section merges the HHI aggregates, constructs the quartile-by-instrument interactions, and re-estimates the heterogeneous IV effects alongside balance checks across concentration groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda076e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi_data = (\n",
    "    panel5.merge(pd.read_stata(RAW_DATA[\"hhi\"]), on=\"county_fips\", how=\"inner\")\n",
    "    .query(\"semi_intens == 1\")\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "hhi_data = hhi_data.sort_values(\"comp_wtd\").reset_index(drop=True)\n",
    "rank = np.arange(1, len(hhi_data) + 1)\n",
    "hhi_data[\"group\"] = np.ceil(4 * rank / len(hhi_data)).astype(int)\n",
    "hhi_data.loc[hhi_data[\"group\"] > 4, \"group\"] = 4\n",
    "\n",
    "for i in range(1, 5):\n",
    "    col = f\"g{i}\"\n",
    "    hhi_data[col] = (hhi_data[\"group\"] == i).astype(int)\n",
    "    hhi_data[f\"xg{i}\"] = hhi_data[\"ltotal_dollars\"] * hhi_data[col]\n",
    "    hhi_data[f\"zg{i}\"] = hhi_data[\"log_spending_iv5\"] * hhi_data[col]\n",
    "\n",
    "hhi_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489befdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhi_formula = build_iv_formula(\n",
    "    outcome=\"lw_cites_sub\",\n",
    "    endog=[f\"xg{i}\" for i in range(1, 5)],\n",
    "    instruments=[f\"zg{i}\" for i in range(1, 5)],\n",
    "    controls=[\"avg_wages\", \"pop\", \"emp\"],\n",
    "    fe=(\"county_fips\", \"fyear\", \"state_yr\"),\n",
    ")\n",
    "hhi_model = IV2SLS.from_formula(hhi_formula, data=hhi_data).fit(\n",
    "    cov_type=\"clustered\", clusters=hhi_data[\"county_fips\"]\n",
    ")\n",
    "\n",
    "coef_terms = [f\"xg{i}\" for i in range(1, 5)]\n",
    "hhi_results = pd.DataFrame(\n",
    "    {\n",
    "        \"group\": [f\"Q{i}\" for i in range(1, 5)],\n",
    "        \"coef\": [hhi_model.params[term] for term in coef_terms],\n",
    "        \"std_err\": [hhi_model.std_errors[term] for term in coef_terms],\n",
    "    }\n",
    ")\n",
    "hhi_results[\"ci_low\"] = hhi_results[\"coef\"] - 1.96 * hhi_results[\"std_err\"]\n",
    "hhi_results[\"ci_high\"] = hhi_results[\"coef\"] + 1.96 * hhi_results[\"std_err\"]\n",
    "\n",
    "baseline = pd.DataFrame(\n",
    "    {\n",
    "        \"group\": [\"Baseline (pooled)\"],\n",
    "        \"coef\": [0.1122621],\n",
    "        \"std_err\": [0.0369543],\n",
    "    }\n",
    ")\n",
    "baseline[\"ci_low\"] = baseline[\"coef\"] - 1.96 * baseline[\"std_err\"]\n",
    "baseline[\"ci_high\"] = baseline[\"coef\"] + 1.96 * baseline[\"std_err\"]\n",
    "\n",
    "hhi_plot_data = pd.concat([hhi_results, baseline], ignore_index=True)\n",
    "\n",
    "positions = np.arange(len(hhi_plot_data))\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.errorbar(\n",
    "    positions,\n",
    "    hhi_plot_data[\"coef\"],\n",
    "    yerr=1.96 * hhi_plot_data[\"std_err\"],\n",
    "    fmt=\"o\",\n",
    "    color=\"#1f77b4\",\n",
    "    capsize=5,\n",
    ")\n",
    "ax.axhline(0, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(hhi_plot_data[\"group\"])\n",
    "ax.set(\n",
    "    title=\"Treatment Effects by Concentration Quartile\",\n",
    "    xlabel=\"Group\",\n",
    "    ylabel=\"Estimated treatment effect\",\n",
    ")\n",
    "fig.tight_layout()\n",
    "fig_path = FIGURE_DIR / \"hhi_group_effects.png\"\n",
    "fig.savefig(fig_path, dpi=300)\n",
    "hhi_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_vars = [\"inventor_share\", \"tech_emp_share\", \"emp_share\", \"pop\"]\n",
    "\n",
    "group_means = hhi_data.groupby(\"group\")[balance_vars].mean().round(4)\n",
    "\n",
    "group_counts = hhi_data.groupby(\"group\").size().rename(\"n_obs\")\n",
    "\n",
    "balance_table = group_means.join(group_counts)\n",
    "balance_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e90b7",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ea7b5b",
   "metadata": {},
   "source": [
    "- Figures are saved to `../figures/` and tables can be exported from the DataFrames displayed above.\n",
    "- Cluster-robust standard errors follow the Stata specifications (clustered at the county level).\n",
    "- Adjust the `RAW_DATA` dictionary if your folder structure differs or if you add alternative data versions.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
